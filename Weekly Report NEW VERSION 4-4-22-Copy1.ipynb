{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue, size=\"10\">**NEWS PUBLISHER**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:38:27.954765Z",
     "start_time": "2022-01-27T20:38:27.914670Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta\n",
    "import _datetime\n",
    "import datetime\n",
    "import time\n",
    "import calendar\n",
    "import glob\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "pd.options.display.max_colwidth = 100\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "# For connecting to google sheets\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from df2gspread import df2gspread as d2g\n",
    "# Change this line to point to your own service token file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/Users/dicharryd/service_token.json\"\n",
    "# Configure the connection \n",
    "scope = ['https://spreadsheets.google.com/feeds']\n",
    "# Give the path to the Service Account Credential json file \n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('/Users/dicharryd/service_token.json',scope)\n",
    "# Authorise your Notebook\n",
    "gc = gspread.authorize(credentials)\n",
    "# spreadsheet ID from URL\n",
    "spreadsheet_key = '1VpimYGT1nZ20KmsvR6ILs1dIkC4mlDE_0uMsz6ckCDk' #\"NEW weekly features\"\n",
    "#make sure sheet is shared with bergstresser@dj-users.iam.gserviceaccount.com\n",
    "\n",
    "#************************************************************************\n",
    "\n",
    "#Connecting to BigQuery\n",
    "client = bigquery.Client()\n",
    "\n",
    "def query_calls(client, query):\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.use_legacy_sql = False\n",
    "    query_job = client.query(query, job_config=job_config)\n",
    "    results = query_job.result()\n",
    "    return results\n",
    "\n",
    "def job_setup(client, query, dataset, table, write_disposition):\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    table_ref = client.dataset(dataset).table(table)\n",
    "    job_config.destination = table_ref\n",
    "    job_config.use_legacy_sql = False\n",
    "    job_config.write_disposition = write_disposition\n",
    "   \n",
    "    query_job = client.query(\n",
    "    query,\n",
    "    location='US',\n",
    "    job_config=job_config)\n",
    "\n",
    "    query_job.result()\n",
    "    print('Query results loaded to table {}'.format(table_ref.path))\n",
    "    print('Query last completed at {}'.format(datetime.datetime.now()))\n",
    "    last_modified = client.get_table(dataset + '.' + table).modified\n",
    "    print('Table last modified at {} GMT timezone'.format(last_modified))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T14:53:05.837472Z",
     "start_time": "2022-01-27T14:53:05.832733Z"
    }
   },
   "source": [
    "# REFERRAL TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:38:42.911096Z",
     "start_time": "2022-01-27T20:38:27.957740Z"
    }
   },
   "outputs": [],
   "source": [
    "# query = '''\n",
    "\n",
    "# select channel,\n",
    "# CASE WHEN news_tab = 1 THEN \"News Tab\"\n",
    "# when referrer = \"googleapis.com\" THEN \"Google\"\n",
    "# when referrer LIKE \"google.%\" THEN \"Google\"\n",
    "# ELSE NET.REG_DOMAIN(referrer) END as referrer, \n",
    "# -- CASE WHEN channel LIKE \"%arket%\" THEN \"MarketWatch\" \n",
    "# -- ELSE NET.REG_DOMAIN(referrer) END as new_channel,\n",
    "# sum(views) as views, \n",
    "# count(distinct unique_id) as uniques from (\n",
    "#         SELECT\n",
    "#         DISTINCT NET.REG_DOMAIN(visit_referrer) as referrer,\n",
    "#         DATE(date_time) as read_time,\n",
    "#         IF(REGEXP_CONTAINS(page_url, 'utm_medium=news_tab') AND NET.REG_DOMAIN(visit_referrer) = 'facebook.com', 1, 0) as news_tab,\n",
    "#         #IF(REGEXP_CONTAINS(post_evar56, 'personalized'), 1, 0) as locked,\n",
    "#         IF(post_page_event = '0' AND (CAST(exclude_hit AS INT64) <= 0 AND hit_source NOT IN ('5', '8', '9')),1,0) as views,\n",
    "#         #IF(post_prop27 IN ('WSJ_sub_yes'), 1, 0) as sub_status,\n",
    "#         CONCAT(post_visid_high, post_visid_low) as unique_id,\n",
    "#         visit_num,\n",
    "#         channel,\n",
    "#         #IF(prop1 = 'Article', 1, 0) as article,\n",
    "#         #visit_page_num,\n",
    "#         #IF(REGEXP_CONTAINS(visit_start_pagename, 'Article'), 1, 0) as article_visit,\n",
    "#         #IF(page_event_var2 = 'WSJ_Article_social_share', 1, 0) as share,\n",
    "#         #prop10\n",
    "        \n",
    "#         FROM\n",
    "#         `djomniture.cipomniture_djglobal.*` \n",
    "#         WHERE _TABLE_SUFFIX BETWEEN '2021_12' AND '2022_12'\n",
    "#         #and DATE(TIMESTAMP(CONCAT(SUBSTR(_TABLE_SUFFIX,1,4),'-',SUBSTR(_TABLE_SUFFIX,-2),'-','01'))) BETWEEN \"2021-12-01\" AND \"2021-12-31\"               \n",
    "#         #and DATE(date_time) BETWEEN DATE(DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -7 DAY), DAY)) AND DATE(DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -1 DAY), DAY))    \n",
    "#         and DATE(date_time) BETWEEN DATE_ADD(DATE_TRUNC(CURRENT_DATE(), WEEK(SUNDAY)), INTERVAL -6 DAY) AND DATE_TRUNC(CURRENT_DATE(), WEEK(SUNDAY))\n",
    "#         and SAFE_CAST(exclude_hit AS INT64) <= 0\n",
    "#         AND hit_source NOT IN ('5',\n",
    "#                                 '8',\n",
    "#                                 '9')\n",
    "#         #AND (REGEXP_CONTAINS(page_url, 'wsj[.com|.net]')\n",
    "#         #and channel IN ('Online Journal')\n",
    "# ) \n",
    "# where (referrer IN (\"apple.news\", 'facebook.com','news_tab','google.com') OR (referrer LIKE \"google.%\" OR referrer = \"googleapis.com\"))\n",
    "# group by channel, referrer\n",
    "# order by channel, referrer \n",
    "\n",
    "# '''\n",
    "\n",
    "# referralthisweek = query_calls(client, query).to_dataframe()\n",
    "# referralthisweek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:39:31.312523Z",
     "start_time": "2022-01-27T20:38:42.914737Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:51: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  referralthisweek['channel'] =    pd.np.where(referralthisweek['channel'].str.contains(\"arket\"),\"MarketWatch\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:54: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['channel'].str.contains(\"wsj-video\"),\"Online Journal\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:55: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['channel'].str.contains(\"barrons-video\"),\"Barrons\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:56: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['channel'].str.contains(\"Barrons Online\"),\"Barrons\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:63: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  referralthisweek['referrer'] = pd.np.where(referralthisweek['referrer'].str.contains(\"goog\"),\"Google\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:64: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer'].str.contains(\"android.gm\"),\"Google\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:65: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer']==\"facebook.com\",\"Facebook\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:66: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer']==\"News Tab\",\"FB News\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:67: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer'].str.contains(\"twitter\"),\"Twitter\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:68: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer']==\"t.co\",\"Twitter\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:69: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer'].str.contains(\"lnkd\"),\"LinkedIn\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:70: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer'].str.contains(\"linkedin\"),\"LinkedIn\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:71: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer']==\"linkedin.com\",\"LinkedIn\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:72: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer'].str.contains(\"yahoo\"),\"Yahoo\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:73: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer']==\"wsj.com\",\"Direct\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:74: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer'].str.contains(\"robinhood\"),\"Robinhood\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:75: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer'].str.contains(\"wsj_RHF\"),\"Robinhood\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:76: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer']==\"apple.news\",\"Apple News\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:77: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer']==\"instagram.com\",\"Instagram\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:78: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer']==\"drudgereport.com\",\"Drudge Report\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:79: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer']==\"ampproject.org\",\"Google\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:80: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralthisweek['referrer']==\"bing.com\",\"Bing\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:134: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  referralpriorweek['channel'] =    pd.np.where(referralpriorweek['channel'].str.contains(\"arket\"),\"MarketWatch\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:135: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['channel'].str.contains(\"wsj-video\"),\"Online Journal\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:136: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['channel'].str.contains(\"barrons-video\"),\"Barrons\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:137: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['channel'].str.contains(\"Barrons Online\"),\"Barrons\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:143: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  referralpriorweek['referrer'] = pd.np.where(referralpriorweek['referrer'].str.contains(\"goog\"),\"Google\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:144: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer'].str.contains(\"android.gm\"),\"Google\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:145: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer']==\"facebook.com\",\"Facebook\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:146: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer']==\"News Tab\",\"FB News\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:147: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer'].str.contains(\"twitter\"),\"Twitter\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:148: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer']==\"t.co\",\"Twitter\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:149: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer'].str.contains(\"lnkd\"),\"LinkedIn\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:150: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer'].str.contains(\"linkedin\"),\"LinkedIn\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:151: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer']==\"linkedin.com\",\"LinkedIn\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:152: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer'].str.contains(\"yahoo\"),\"Yahoo\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:153: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer']==\"wsj.com\",\"Direct\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:154: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer'].str.contains(\"robinhood\"),\"Robinhood\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:155: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer'].str.contains(\"wsj_RHF\"),\"Robinhood\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:156: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer']==\"apple.news\",\"Apple News\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:157: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer']==\"instagram.com\",\"Instagram\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:158: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer']==\"drudgereport.com\",\"Drudge Report\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:159: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer']==\"ampproject.org\",\"Google\",\n",
      "/var/folders/y6/ncpp7cyx1jz11rm61jlv5js80000gq/T/ipykernel_48862/1929484052.py:160: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  pd.np.where(referralpriorweek['referrer']==\"bing.com\",\"Bing\",\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>channel</th>\n",
       "      <th>Week</th>\n",
       "      <th>referrer</th>\n",
       "      <th>views</th>\n",
       "      <th>uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>thisweek</td>\n",
       "      <td>Google</td>\n",
       "      <td>6687936</td>\n",
       "      <td>5509128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Online Journal</td>\n",
       "      <td>thisweek</td>\n",
       "      <td>Google</td>\n",
       "      <td>5725380</td>\n",
       "      <td>5170041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>thisweek</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>2601848</td>\n",
       "      <td>2099939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Online Journal</td>\n",
       "      <td>thisweek</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>1603922</td>\n",
       "      <td>1433126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Online Journal</td>\n",
       "      <td>thisweek</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2249301</td>\n",
       "      <td>1262406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>129</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>priorweek</td>\n",
       "      <td>schoology.com</td>\n",
       "      <td>1684</td>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>130</td>\n",
       "      <td>Online Journal</td>\n",
       "      <td>priorweek</td>\n",
       "      <td>appspace.com</td>\n",
       "      <td>1047</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>131</td>\n",
       "      <td>Online Journal</td>\n",
       "      <td>priorweek</td>\n",
       "      <td>vanguard.com</td>\n",
       "      <td>3060</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>132</td>\n",
       "      <td>Online Journal</td>\n",
       "      <td>priorweek</td>\n",
       "      <td>stevequayle.com</td>\n",
       "      <td>1033</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>133</td>\n",
       "      <td>Online Journal</td>\n",
       "      <td>priorweek</td>\n",
       "      <td>substack.com</td>\n",
       "      <td>1093</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index         channel       Week         referrer    views  uniques\n",
       "0        0     MarketWatch   thisweek           Google  6687936  5509128\n",
       "1        1  Online Journal   thisweek           Google  5725380  5170041\n",
       "2        2     MarketWatch   thisweek            Yahoo  2601848  2099939\n",
       "3        3  Online Journal   thisweek         Facebook  1603922  1433126\n",
       "4        4  Online Journal   thisweek           Direct  2249301  1262406\n",
       "..     ...             ...        ...              ...      ...      ...\n",
       "269    129     MarketWatch  priorweek    schoology.com     1684     1049\n",
       "270    130  Online Journal  priorweek     appspace.com     1047     1047\n",
       "271    131  Online Journal  priorweek     vanguard.com     3060     1037\n",
       "272    132  Online Journal  priorweek  stevequayle.com     1033     1020\n",
       "273    133  Online Journal  priorweek     substack.com     1093     1002\n",
       "\n",
       "[274 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "referral_query1 = '''\n",
    "select * from (\n",
    "\n",
    "select channel,\n",
    "CASE WHEN news_tab = 1 THEN \"News Tab\"\n",
    "when referrer = \"googleapis.com\" THEN \"Google\"\n",
    "when referrer LIKE \"google.%\" THEN \"Google\"\n",
    "ELSE NET.REG_DOMAIN(referrer) END as referrer, \n",
    "-- CASE WHEN channel LIKE \"%arket%\" THEN \"MarketWatch\" \n",
    "-- ELSE NET.REG_DOMAIN(referrer) END as new_channel,\n",
    "sum(views) as views, \n",
    "count(distinct unique_id) as uniques from (\n",
    "        SELECT\n",
    "        DISTINCT NET.REG_DOMAIN(visit_referrer) as referrer,\n",
    "        DATE(date_time) as read_time,\n",
    "        IF(REGEXP_CONTAINS(page_url, 'utm_medium=news_tab') AND NET.REG_DOMAIN(visit_referrer) = 'facebook.com', 1, 0) as news_tab,\n",
    "        #IF(REGEXP_CONTAINS(post_evar56, 'personalized'), 1, 0) as locked,\n",
    "        IF(post_page_event = '0' AND (CAST(exclude_hit AS INT64) <= 0 AND hit_source NOT IN ('5', '8', '9')),1,0) as views,\n",
    "        #IF(post_prop27 IN ('WSJ_sub_yes'), 1, 0) as sub_status,\n",
    "        CONCAT(post_visid_high, post_visid_low) as unique_id,\n",
    "        visit_num,\n",
    "        channel,\n",
    "        #IF(prop1 = 'Article', 1, 0) as article,\n",
    "        #visit_page_num,\n",
    "        #IF(REGEXP_CONTAINS(visit_start_pagename, 'Article'), 1, 0) as article_visit,\n",
    "        #IF(page_event_var2 = 'WSJ_Article_social_share', 1, 0) as share,\n",
    "        #prop10\n",
    "        \n",
    "        FROM\n",
    "        `djomniture.cipomniture_djglobal.*` \n",
    "        WHERE _TABLE_SUFFIX BETWEEN '2021_12' AND '2022_12'\n",
    "        #and DATE(TIMESTAMP(CONCAT(SUBSTR(_TABLE_SUFFIX,1,4),'-',SUBSTR(_TABLE_SUFFIX,-2),'-','01'))) BETWEEN \"2021-12-01\" AND \"2021-12-31\"               \n",
    "        #and DATE(date_time) BETWEEN DATE(DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -7 DAY), DAY)) AND DATE(DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -1 DAY), DAY))    \n",
    "        and DATE(date_time) BETWEEN DATE_ADD(DATE_TRUNC(CURRENT_DATE(), WEEK(SUNDAY)), INTERVAL -6 DAY) AND DATE_TRUNC(CURRENT_DATE(), WEEK(SUNDAY))\n",
    "        and SAFE_CAST(exclude_hit AS INT64) <= 0\n",
    "        AND hit_source NOT IN ('5',\n",
    "                                '8',\n",
    "                                '9')\n",
    "        #AND (REGEXP_CONTAINS(page_url, 'wsj[.com|.net]')\n",
    "        #and channel IN ('Online Journal')\n",
    ") \n",
    "#where (referrer IN (\"apple.news\", 'facebook.com','news_tab','google.com') OR (referrer LIKE \"google.%\" OR referrer = \"googleapis.com\"))\n",
    "group by channel, referrer\n",
    "order by views DESC\n",
    "\n",
    ") where uniques >1000\n",
    "order by uniques DESC\n",
    "'''\n",
    "referralthisweek = query_calls(client, referral_query1).to_dataframe()\n",
    "\n",
    "referralthisweek['channel'] =    pd.np.where(referralthisweek['channel'].str.contains(\"arket\"),\"MarketWatch\", \n",
    "                            #pd.np.where(referralthisweek['channel'].str.contains(\"Online Journal\"),\"WSJ\", \n",
    "                            #pd.np.where(referralthisweek['channel'].str.contains(\"WSJ\"),\"WSJ\",\n",
    "                            pd.np.where(referralthisweek['channel'].str.contains(\"wsj-video\"),\"Online Journal\",\n",
    "                            pd.np.where(referralthisweek['channel'].str.contains(\"barrons-video\"),\"Barrons\", \n",
    "                            pd.np.where(referralthisweek['channel'].str.contains(\"Barrons Online\"),\"Barrons\",\n",
    "                                                                               referralthisweek['channel']))))\n",
    "\n",
    "referralthisweek = referralthisweek.loc[referralthisweek['channel'].isin(['Barrons','Online Journal','MarketWatch'])]\n",
    "referralthisweek = referralthisweek.groupby(['channel','referrer']).sum().reset_index()\n",
    "referralthisweek.insert(1, 'Week', 'thisweek') \n",
    "\n",
    "referralthisweek['referrer'] = pd.np.where(referralthisweek['referrer'].str.contains(\"goog\"),\"Google\",\n",
    "                          pd.np.where(referralthisweek['referrer'].str.contains(\"android.gm\"),\"Google\",\n",
    "                                     pd.np.where(referralthisweek['referrer']==\"facebook.com\",\"Facebook\",\n",
    "                                         pd.np.where(referralthisweek['referrer']==\"News Tab\",\"FB News\",\n",
    "                             pd.np.where(referralthisweek['referrer'].str.contains(\"twitter\"),\"Twitter\",\n",
    "                                             pd.np.where(referralthisweek['referrer']==\"t.co\",\"Twitter\",\n",
    "                                pd.np.where(referralthisweek['referrer'].str.contains(\"lnkd\"),\"LinkedIn\",\n",
    "                            pd.np.where(referralthisweek['referrer'].str.contains(\"linkedin\"),\"LinkedIn\",\n",
    "                                     pd.np.where(referralthisweek['referrer']==\"linkedin.com\",\"LinkedIn\",\n",
    "                               pd.np.where(referralthisweek['referrer'].str.contains(\"yahoo\"),\"Yahoo\",\n",
    "                                          pd.np.where(referralthisweek['referrer']==\"wsj.com\",\"Direct\",\n",
    "                           pd.np.where(referralthisweek['referrer'].str.contains(\"robinhood\"),\"Robinhood\",\n",
    "                             pd.np.where(referralthisweek['referrer'].str.contains(\"wsj_RHF\"),\"Robinhood\",\n",
    "                                       pd.np.where(referralthisweek['referrer']==\"apple.news\",\"Apple News\",\n",
    "                                    pd.np.where(referralthisweek['referrer']==\"instagram.com\",\"Instagram\",\n",
    "                                 pd.np.where(referralthisweek['referrer']==\"drudgereport.com\",\"Drudge Report\",\n",
    "                                   pd.np.where(referralthisweek['referrer']==\"ampproject.org\",\"Google\",\n",
    "                                         pd.np.where(referralthisweek['referrer']==\"bing.com\",\"Bing\",\n",
    "                                                                             referralthisweek['referrer']))))))))))))))))))\n",
    "referralthisweek = referralthisweek.groupby(['channel','Week','referrer']).sum().sort_values(by='uniques',ascending=False).reset_index()\n",
    "############################################################################\n",
    "\n",
    "referral_query2 = '''\n",
    "select * from (\n",
    "\n",
    "select channel,\n",
    "CASE WHEN news_tab = 1 THEN \"News Tab\"\n",
    "when referrer = \"googleapis.com\" THEN \"Google\"\n",
    "when referrer LIKE \"google.%\" THEN \"Google\"\n",
    "ELSE NET.REG_DOMAIN(referrer) END as referrer, \n",
    "-- CASE WHEN channel LIKE \"%arket%\" THEN \"MarketWatch\" \n",
    "-- ELSE NET.REG_DOMAIN(referrer) END as new_channel,\n",
    "sum(views) as views, \n",
    "count(distinct unique_id) as uniques from (\n",
    "        SELECT\n",
    "        DISTINCT NET.REG_DOMAIN(visit_referrer) as referrer,\n",
    "        DATE(date_time) as read_time,\n",
    "        IF(REGEXP_CONTAINS(page_url, 'utm_medium=news_tab') AND NET.REG_DOMAIN(visit_referrer) = 'facebook.com', 1, 0) as news_tab,\n",
    "        #IF(REGEXP_CONTAINS(post_evar56, 'personalized'), 1, 0) as locked,\n",
    "        IF(post_page_event = '0' AND (CAST(exclude_hit AS INT64) <= 0 AND hit_source NOT IN ('5', '8', '9')),1,0) as views,\n",
    "        #IF(post_prop27 IN ('WSJ_sub_yes'), 1, 0) as sub_status,\n",
    "        CONCAT(post_visid_high, post_visid_low) as unique_id,\n",
    "        visit_num,\n",
    "        channel,\n",
    "        #IF(prop1 = 'Article', 1, 0) as article,\n",
    "        #visit_page_num,\n",
    "        #IF(REGEXP_CONTAINS(visit_start_pagename, 'Article'), 1, 0) as article_visit,\n",
    "        #IF(page_event_var2 = 'WSJ_Article_social_share', 1, 0) as share,\n",
    "        #prop10\n",
    "        \n",
    "        FROM\n",
    "        `djomniture.cipomniture_djglobal.*` \n",
    "        WHERE _TABLE_SUFFIX BETWEEN '2021_12' AND '2022_12'\n",
    "        #and DATE(TIMESTAMP(CONCAT(SUBSTR(_TABLE_SUFFIX,1,4),'-',SUBSTR(_TABLE_SUFFIX,-2),'-','01'))) BETWEEN \"2021-12-01\" AND \"2021-12-31\"               \n",
    "        #and DATE(date_time) BETWEEN DATE(DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -14 DAY), DAY)) AND DATE(DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -8 DAY), DAY))    \n",
    "        and DATE(date_time) between DATE_ADD(DATE_TRUNC(CURRENT_DATE(), WEEK(SUNDAY)), INTERVAL -13 DAY) AND DATE_ADD(DATE_TRUNC(CURRENT_DATE(), WEEK(SUNDAY)), INTERVAL -7 DAY)        \n",
    "        and SAFE_CAST(exclude_hit AS INT64) <= 0\n",
    "        AND hit_source NOT IN ('5',\n",
    "                                '8',\n",
    "                                '9')\n",
    "        #AND (REGEXP_CONTAINS(page_url, 'wsj[.com|.net]')\n",
    "        #and channel IN ('Online Journal')\n",
    ") \n",
    "#where (referrer IN (\"apple.news\", 'facebook.com','news_tab','google.com') OR (referrer LIKE \"google.%\" OR referrer = \"googleapis.com\"))\n",
    "group by channel, referrer\n",
    "order by views DESC \n",
    "\n",
    ") where uniques >1000\n",
    "order by uniques DESC\n",
    "'''\n",
    "referralpriorweek = query_calls(client, referral_query2).to_dataframe()\n",
    "referralpriorweek['channel'] =    pd.np.where(referralpriorweek['channel'].str.contains(\"arket\"),\"MarketWatch\", \n",
    "                            pd.np.where(referralpriorweek['channel'].str.contains(\"wsj-video\"),\"Online Journal\",\n",
    "                            pd.np.where(referralpriorweek['channel'].str.contains(\"barrons-video\"),\"Barrons\", \n",
    "                            pd.np.where(referralpriorweek['channel'].str.contains(\"Barrons Online\"),\"Barrons\", \n",
    "                            referralpriorweek['channel']))))\n",
    "referralpriorweek = referralpriorweek.loc[referralpriorweek['channel'].isin(['Barrons','Online Journal','MarketWatch'])]\n",
    "referralpriorweek = referralpriorweek.groupby(['channel','referrer']).sum().reset_index()\n",
    "referralpriorweek.insert(1, 'Week', 'priorweek') \n",
    "\n",
    "referralpriorweek['referrer'] = pd.np.where(referralpriorweek['referrer'].str.contains(\"goog\"),\"Google\",\n",
    "                          pd.np.where(referralpriorweek['referrer'].str.contains(\"android.gm\"),\"Google\",\n",
    "                                     pd.np.where(referralpriorweek['referrer']==\"facebook.com\",\"Facebook\",\n",
    "                                         pd.np.where(referralpriorweek['referrer']==\"News Tab\",\"FB News\",\n",
    "                             pd.np.where(referralpriorweek['referrer'].str.contains(\"twitter\"),\"Twitter\",\n",
    "                                             pd.np.where(referralpriorweek['referrer']==\"t.co\",\"Twitter\",\n",
    "                                pd.np.where(referralpriorweek['referrer'].str.contains(\"lnkd\"),\"LinkedIn\",\n",
    "                            pd.np.where(referralpriorweek['referrer'].str.contains(\"linkedin\"),\"LinkedIn\",\n",
    "                                     pd.np.where(referralpriorweek['referrer']==\"linkedin.com\",\"LinkedIn\",\n",
    "                               pd.np.where(referralpriorweek['referrer'].str.contains(\"yahoo\"),\"Yahoo\",\n",
    "                                          pd.np.where(referralpriorweek['referrer']==\"wsj.com\",\"Direct\",\n",
    "                           pd.np.where(referralpriorweek['referrer'].str.contains(\"robinhood\"),\"Robinhood\",\n",
    "                             pd.np.where(referralpriorweek['referrer'].str.contains(\"wsj_RHF\"),\"Robinhood\",\n",
    "                                       pd.np.where(referralpriorweek['referrer']==\"apple.news\",\"Apple News\",\n",
    "                                    pd.np.where(referralpriorweek['referrer']==\"instagram.com\",\"Instagram\",\n",
    "                                 pd.np.where(referralpriorweek['referrer']==\"drudgereport.com\",\"Drudge Report\",\n",
    "                                   pd.np.where(referralpriorweek['referrer']==\"ampproject.org\",\"Google\",\n",
    "                                         pd.np.where(referralpriorweek['referrer']==\"bing.com\",\"Bing\",\n",
    "                                                                             referralpriorweek['referrer']))))))))))))))))))\n",
    "referralpriorweek = referralpriorweek.groupby(['channel','Week','referrer']).sum().sort_values(by='uniques',ascending=False).reset_index()\n",
    "############################################################################\n",
    "combined = pd.concat([referralthisweek,referralpriorweek], sort=False).reset_index()\n",
    "############################################################################\n",
    "# Set the sheet name you want to upload data to and the start cell where the upload data begins \n",
    "# wks_name = 'referral'\n",
    "# cell_of_start_df = 'a1'\n",
    "# # upload the dataframe of the clients we want to delete\n",
    "# d2g.upload(combined,\n",
    "#            spreadsheet_key,\n",
    "#            wks_name,\n",
    "#            credentials=credentials,\n",
    "#            col_names=True,\n",
    "#            row_names=False,\n",
    "#            start_cell = cell_of_start_df,\n",
    "#            clean=True)\n",
    "# print ('The sheet is updated successfully')\n",
    "combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEBSTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:39:38.927833Z",
     "start_time": "2022-01-27T20:39:31.315892Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sheet is updated successfully\n"
     ]
    }
   ],
   "source": [
    "#Opening the worksheet by using Worksheet ID\n",
    "workbook = gc.open_by_key('1LeCZ7-3E-tZyd9OAYAqHIOF-y4EIpnE0eKllL1wE6ks')\n",
    "sheet = workbook.worksheet('Landing Articles (All)')\n",
    "values = sheet.get_all_values()\n",
    "webstories = pd.DataFrame(values[1:], columns = values[0])\n",
    "webstories['Day'] = pd.to_datetime(webstories['Day'])\n",
    "webstories['Pageviews'] = webstories['Pageviews'].astype(int)\n",
    "############################################################################\n",
    "webstories_thisweek = webstories.copy(deep=True)\n",
    "start_date = ((datetime.datetime.now() - timedelta(days=datetime.datetime.now().weekday() +1)) - timedelta(days=7))\n",
    "end_date = (datetime.datetime.now() - timedelta(days=datetime.datetime.now().weekday() +1))\n",
    "mask = (webstories_thisweek['Day'] > start_date) & (webstories_thisweek['Day'] <= end_date) \n",
    "webstories_thisweek = webstories_thisweek.loc[mask]\n",
    "webstories_thisweek = webstories_thisweek.groupby('Product').sum().reset_index()\n",
    "webstories_thisweek.insert(0, 'Week', 'thisweek') \n",
    "############################################################################\n",
    "webstories_priorweek = webstories.copy(deep=True)\n",
    "start_date = ((datetime.datetime.now() - timedelta(days=datetime.datetime.now().weekday() +1)) - timedelta(days=14))\n",
    "end_date =   ((datetime.datetime.now() - timedelta(days=datetime.datetime.now().weekday() +1)) - timedelta(days=7))\n",
    "mask = (webstories_priorweek['Day'] > start_date) & (webstories_priorweek['Day'] <= end_date) \n",
    "webstories_priorweek = webstories_priorweek.loc[mask]\n",
    "webstories_priorweek = webstories_priorweek.groupby('Product').sum().reset_index()\n",
    "webstories_priorweek.insert(0, 'Week', 'priorweek') \n",
    "############################################################################\n",
    "webstories_combined = pd.concat([webstories_thisweek,webstories_priorweek], sort=False).reset_index()\n",
    "webstories_combined['Product'] =    pd.np.where(webstories_combined['Product'].str.contains(\"WSJ\"),\"Online Journal\", webstories_combined['Product'])\n",
    "############################################################################\n",
    "# Set the sheet name you want to upload data to and the start cell where the upload data begins \n",
    "wks_name = 'webstories'\n",
    "cell_of_start_df = 'a1'\n",
    "# upload the dataframe of the clients we want to delete\n",
    "d2g.upload(webstories_combined,\n",
    "           spreadsheet_key,\n",
    "           wks_name,\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = cell_of_start_df,\n",
    "           clean=True)\n",
    "print ('The sheet is updated successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHOWCASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:39:44.657334Z",
     "start_time": "2022-01-27T20:39:38.930932Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sheet is updated successfully\n"
     ]
    }
   ],
   "source": [
    "#Opening the worksheet by using Worksheet ID\n",
    "workbook = gc.open_by_key('1ItBd7UDJPlKq-k71vzTLDxCmjIVcla48NG3Umd89Zow')\n",
    "sheet = workbook.worksheet('Google UTM')\n",
    "values = sheet.get_all_values()\n",
    "showcase = pd.DataFrame(values[1:], columns = values[0])\n",
    "showcase['Day'] = pd.to_datetime(showcase['Day'])\n",
    "showcase['Pageviews'] = showcase['Pageviews'].astype(int)\n",
    "############################################################################\n",
    "showcase_thisweek = showcase.copy(deep=True)\n",
    "start_date = ((datetime.datetime.now() - timedelta(days=datetime.datetime.now().weekday() +1)) - timedelta(days=7))\n",
    "end_date = (datetime.datetime.now() - timedelta(days=datetime.datetime.now().weekday() +1))\n",
    "mask = (showcase_thisweek['Day'] > start_date) & (showcase_thisweek['Day'] <= end_date) \n",
    "showcase_thisweek = showcase_thisweek.loc[mask]\n",
    "showcase_thisweek = showcase_thisweek.groupby('Product').sum().reset_index()\n",
    "showcase_thisweek.insert(0, 'Week', 'thisweek') \n",
    "############################################################################\n",
    "showcase_priorweek = showcase.copy(deep=True)\n",
    "start_date = ((datetime.datetime.now() - timedelta(days=datetime.datetime.now().weekday() +1)) - timedelta(days=14))\n",
    "end_date =   ((datetime.datetime.now() - timedelta(days=datetime.datetime.now().weekday() +1)) - timedelta(days=7))\n",
    "mask = (showcase_priorweek['Day'] > start_date) & (showcase_priorweek['Day'] <= end_date) \n",
    "showcase_priorweek = showcase_priorweek.loc[mask]\n",
    "############################################################################\n",
    "showcase_priorweek = showcase_priorweek.groupby('Product').sum().reset_index()\n",
    "showcase_priorweek.insert(0, 'Week', 'priorweek') \n",
    "############################################################################\n",
    "showcase_combined = pd.concat([showcase_thisweek,showcase_priorweek], sort=False).reset_index()\n",
    "showcase_combined['Product'] =    pd.np.where(showcase_combined['Product'].str.contains(\"WSJ\"),\"Online Journal\", showcase_combined['Product'])\n",
    "############################################################################\n",
    "# Set the sheet name you want to upload data to and the start cell where the upload data begins \n",
    "wks_name = 'showcase'\n",
    "cell_of_start_df = 'a1'\n",
    "# upload the dataframe of the clients we want to delete\n",
    "d2g.upload(showcase_combined,\n",
    "           spreadsheet_key,\n",
    "           wks_name,\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = cell_of_start_df,\n",
    "           clean=True)\n",
    "print ('The sheet is updated successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORDERS BY REFERRER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:39:44.669701Z",
     "start_time": "2022-01-27T20:39:44.660584Z"
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "\n",
    "\n",
    "WITH articles AS (SELECT\n",
    "                  DISTINCT\n",
    "                  visit_referrer,\n",
    "                  timestamp(date_time) as read_time,\n",
    "                  IF(REGEXP_CONTAINS(page_url, 'utm_medium=news_tab') AND NET.REG_DOMAIN(visit_referrer) = 'facebook.com', 1, 0) as news_tab,\n",
    "                  IF(REGEXP_CONTAINS(post_evar56, 'personalized'), 1, 0) as locked,\n",
    "                  IF(post_page_event = '0' AND (CAST(exclude_hit AS INT64) <= 0 AND hit_source NOT IN ('5', '8', '9')),1,0) as views,\n",
    "                  IF(post_prop27 IN ('WSJ_sub_yes'), 1, 0) as sub_status,\n",
    "                  CONCAT(post_visid_high, post_visid_low) as unique_id,\n",
    "                  visit_num,\n",
    "                  IF(prop1 = 'Article', 1, 0) as article,\n",
    "                  visit_page_num,\n",
    "                  IF(REGEXP_CONTAINS(visit_start_pagename, 'Article'), 1, 0) as article_visit,\n",
    "                  IF(page_event_var2 = 'WSJ_Article_social_share', 1, 0) as share,\n",
    "                  prop10\n",
    "                  FROM\n",
    "                   `djomniture.cipomniture_djglobal.*` \n",
    "                  WHERE REGEXP_CONTAINS(_TABLE_SUFFIX,r'^\\d{4}$*')\n",
    "    AND _TABLE_SUFFIX BETWEEN '2022_01' AND '2022_12'\n",
    "    AND DATE(date_time) BETWEEN DATE(DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -7 DAY), DAY)) AND DATE(DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -1 DAY), DAY))\n",
    "                  AND SAFE_CAST(exclude_hit AS INT64) <= 0\n",
    "                  AND hit_source NOT IN ('5',\n",
    "                                         '8',\n",
    "                                         '9')\n",
    "                  AND (REGEXP_CONTAINS(page_url, 'wsj[.com|.net]')\n",
    "                  OR channel IN ('Online Journal'))),\n",
    "sales as (SELECT \n",
    "          CONCAT(post_visid_high, post_visid_low) as unique_id,\n",
    "          timestamp(date_time) as subscribe_time,\n",
    "          post_evar39 as conversion_headline,\n",
    "          visit_num,\n",
    "          post_purchaseid,\n",
    "          FROM\n",
    "          `djomniture.cipomniture_djglobal.*`\n",
    "          WHERE REGEXP_CONTAINS(_TABLE_SUFFIX,r'^\\d{4}$*')\n",
    "    AND _TABLE_SUFFIX BETWEEN '2022_01' AND '2022_12'\n",
    "    AND DATE(date_time) BETWEEN DATE(DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -7 DAY), DAY)) AND DATE(DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -1 DAY), DAY))\n",
    "          AND SAFE_CAST(exclude_hit AS INT64) <= 0\n",
    "          AND hit_source NOT IN ('5',\n",
    "                                 '8',\n",
    "                                 '9')\n",
    "          AND REGEXP_CONTAINS(post_event_list, r'^1,|,1,|,1$')\n",
    "          --Relevant order filters go here (i.e. excluding student)\n",
    "          AND REGEXP_CONTAINS(page_url, 'store.wsj.com|buy.wsj.com')\n",
    "          AND channel IN ('Online Journal')),\n",
    "performance as (SELECT\n",
    "CASE WHEN articles.prop10 IN ('MW_mw_RHF','_mw_RHF','WSJ_wsj_RHF','BOL_bar_RHF','cashapprss','WSJ_Euronews','WSJ_wsj_square','_wsj_square') THEN prop10\n",
    "WHEN news_tab = 1 THEN \"News Tab\"\n",
    "WHEN NET.REG_DOMAIN(articles.visit_referrer) IS NULL THEN 'wsj.com'\n",
    "ELSE NET.REG_DOMAIN(articles.visit_referrer) END as referrer,\n",
    "#SAFE_CAST(CONCAT(SUBSTR(SAFE_CAST(EXTRACT(date FROM read_time) as STRING),1,8),'01') as DATE) as month,\n",
    "COUNT(DISTINCT articles.unique_id) as uniques,\n",
    "COUNT(articles.views) as views,\n",
    "COUNT(DISTINCT CONCAT(articles.unique_id, articles.visit_num)) as visits,\n",
    "COUNT(DISTINCT IF(SAFE_CAST(articles.visit_num AS INT64) >1, CONCAT(articles.unique_id), NULL)) as twoplus,\n",
    "COUNT(DISTINCT IF(articles.visit_num = '1', CONCAT(articles.unique_id, articles.visit_num), NULL)) as cold_visits,\n",
    "COUNT(DISTINCT IF(SAFE_CAST(articles.visit_num AS INT64) BETWEEN 2 AND 4, CONCAT(articles.unique_id, articles.visit_num), NULL)) as medium_visits,\n",
    "COUNT(DISTINCT IF(SAFE_CAST(articles.visit_num AS INT64) >= 5, CONCAT(articles.unique_id, articles.visit_num), NULL)) as hot_visits,\n",
    "COUNT(DISTINCT IF(articles.share = 1, CONCAT(articles.unique_id, articles.visit_num, articles.visit_page_num), NULL)) as shares,\n",
    "COUNT(DISTINCT IF(articles.visit_num = sales.visit_num, post_purchaseid, null)) as orders_same_visit,\n",
    "COUNT(DISTINCT post_purchaseid) as orders_7_days,\n",
    "COUNT(DISTINCT post_purchaseid) as purchases,\n",
    "COUNT(DISTINCT articles.unique_id) as unique_ids,\n",
    "COUNT(DISTINCT post_purchaseid)  / COUNT(DISTINCT articles.unique_id) as conversion_rate,\n",
    "SAFE_DIVIDE(COUNT(DISTINCT IF(article = 1 AND locked = 1, CONCAT(articles.unique_id, articles.visit_num, articles.visit_page_num), NULL)), COUNT(DISTINCT IF(article = 1, CONCAT(articles.unique_id, articles.visit_num, articles.visit_page_num), NULL))) as percent_locked,\n",
    "COUNT(DISTINCT IF(article = 1,CONCAT(articles.unique_id, articles.visit_num, articles.visit_page_num), NULL)) as all_articles,\n",
    "COUNT(DISTINCT IF(article = 1 AND locked = 1,CONCAT(articles.unique_id, articles.visit_num, articles.visit_page_num), NULL)) as locked_articles\n",
    "FROM\n",
    "articles\n",
    "LEFT JOIN\n",
    "sales ON \n",
    "articles.unique_id = sales.unique_id\n",
    "AND articles.read_time < sales.subscribe_time\n",
    "AND DATE_DIFF(DATE(sales.subscribe_time), DATE(articles.read_time), DAY) < 7\n",
    "WHERE articles.sub_status = 0\n",
    "AND articles.article_visit = 1\n",
    "GROUP BY\n",
    "referrer),\n",
    "return_visits as (SELECT\n",
    "CASE WHEN articles.prop10 IN ('MW_mw_RHF','_mw_RHF','WSJ_wsj_RHF','BOL_bar_RHF','cashapprss','cashapprss','WSJ_Euronews','WSJ_wsj_square','_wsj_square') THEN articles.prop10\n",
    "WHEN articles.news_tab = 1 THEN \"News Tab\"\n",
    "WHEN NET.REG_DOMAIN(articles.visit_referrer) IS NULL THEN 'wsj.com'\n",
    "ELSE NET.REG_DOMAIN(articles.visit_referrer) END as referrer,\n",
    "#SAFE_CAST(CONCAT(SUBSTR(SAFE_CAST(EXTRACT(date FROM articles.read_time) as STRING),1,8),'01') as DATE) as month,\n",
    "COUNT(DISTINCT IF(returns.read_time > articles.read_time AND DATE_DIFF(DATE(returns.read_time), DATE(articles.read_time), DAY) < 7\n",
    "AND SAFE_CAST(returns.visit_num as INT64) > 1, CONCAT(articles.unique_id, articles.visit_num), NULL)) as returns\n",
    "FROM\n",
    "articles\n",
    "LEFT JOIN\n",
    "articles as returns ON \n",
    "articles.unique_id = returns.unique_id\n",
    "WHERE articles.sub_status = 0\n",
    "AND articles.article_visit = 1\n",
    "AND articles.visit_num = '1'\n",
    "GROUP BY\n",
    "referrer)\n",
    "SELECT\n",
    "*,\n",
    "SAFE_DIVIDE(twoplus, uniques) as return_rate\n",
    "FROM\n",
    "performance\n",
    "LEFT JOIN\n",
    "return_visits\n",
    "USING(referrer)\n",
    "WHERE uniques >= 1000\n",
    "ORDER BY\n",
    "uniques DESC\n",
    "\n",
    "'''\n",
    "\n",
    "orders = query_calls(client, query).to_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLE NEWS-SPECIFIC TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:07.410348Z",
     "start_time": "2022-01-27T20:39:44.673550Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# PULL IN ALL REPORTS BY REGION FROM THE WSJ FOLDER\n",
    "allwsjarticledetailimport = pd.concat([pd.read_csv(f) for f in glob.glob('/Users/dicharryd/Documents/ANP Report/News Publisher/monthlies/wsj/*ArticleDetail_all.csv')], ignore_index = True,sort=False)\n",
    "allwsjarticledetailimport.insert(1,'Region','ALL')\n",
    "allwsjarticledetailimport.insert(1,'channel','wsj')\n",
    "\n",
    "allwsjchannelsummaryimport = pd.concat([pd.read_csv(f) for f in glob.glob('/Users/dicharryd/Documents/ANP Report/News Publisher/monthlies/wsj/*ChannelSummary_all.csv')], ignore_index = True,sort=False)\n",
    "allwsjchannelsummaryimport.insert(1,'Region','ALL')\n",
    "allwsjchannelsummaryimport.insert(1,'channel','wsj')\n",
    "\n",
    "allwsjnotificationsimport = pd.concat([pd.read_csv(f) for f in glob.glob('/Users/dicharryd/Documents/ANP Report/News Publisher/monthlies/wsj/*Notifications_all.csv')], ignore_index = True,sort=False)\n",
    "allwsjnotificationsimport.insert(1,'Region','ALL')\n",
    "allwsjnotificationsimport.insert(1,'channel','wsj')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:07.731810Z",
     "start_time": "2022-01-27T20:40:07.413981Z"
    }
   },
   "outputs": [],
   "source": [
    "allwsjchannelsummaryimport = pd.concat([pd.read_csv(f) for f in glob.glob('/Users/dicharryd/Documents/ANP Report/News Publisher/monthlies/wsj/*ChannelSummary_all.csv')], ignore_index = True,sort=False)\n",
    "allwsjchannelsummaryimport.insert(1,'Region','ALL')\n",
    "allwsjchannelsummaryimport.insert(1,'channel','wsj')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:10.942983Z",
     "start_time": "2022-01-27T20:40:07.734805Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allwsjchannelsummary = allwsjchannelsummaryimport\n",
    "allwsjchannelsummary['Actual Date'] = pd.to_datetime(allwsjchannelsummary['Date'],infer_datetime_format=True)\n",
    "allwsjchannelsummary['Date'] = pd.to_datetime(allwsjchannelsummary['Date'],infer_datetime_format=True)\n",
    "allwsjchannelsummary = allwsjchannelsummary.groupby(['Actual Date','Region','channel']).resample('W-Sun', on='Date').sum().reset_index()\n",
    "allwsjchannelsummary = allwsjchannelsummary.rename(columns={'Date':'Week Ending'})\n",
    "allwsjchannelsummary['MAU Subs Date'] = (allwsjchannelsummary['Actual Date'] == allwsjchannelsummary['Week Ending'])\n",
    "allwsjchannelsummary['MAU Subs Date'] = allwsjchannelsummary['MAU Subs Date'].astype(int)\n",
    "allwsjchannelsummary['Month'] = allwsjchannelsummary['Actual Date'].dt.strftime('%B')\n",
    "allwsjchannelsummary['Week Dates'] = (allwsjchannelsummary['Week Ending'] - timedelta(days=6)).astype(str) + \" - \" + allwsjchannelsummary['Week Ending'].astype(str)\n",
    "allwsjchannelsummary.insert(1,'Timeframe','daily')\n",
    "allwsjchannelsummary = allwsjchannelsummary[['Month','Week Dates','Actual Date','Week Ending','Timeframe','MAU Subs Date','channel','Region','Total Views','Unique Viewers','Reach','Unique Viewers, Subscribers, All Content','Total Engaged Minutes, Apple News+ Subscribers','MAU, Apple News+ Subscribers']].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:10.984400Z",
     "start_time": "2022-01-27T20:40:10.945464Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allwsjchannelsummaryweekly = allwsjchannelsummary.groupby(['Week Dates','Week Ending','channel','Region']).sum().reset_index()\n",
    "allwsjchannelsummaryweekly.insert(1,'Timeframe','weekly')\n",
    "allwsjchannelsummaryweekly = allwsjchannelsummaryweekly[['Week Dates','Week Ending','Timeframe','channel','Region','Total Views','Total Engaged Minutes, Apple News+ Subscribers']].sort_values(by='Week Ending',ascending=False).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:11.014197Z",
     "start_time": "2022-01-27T20:40:10.988829Z"
    }
   },
   "outputs": [],
   "source": [
    "mau = allwsjchannelsummary.copy(deep=True) \n",
    "mau = allwsjchannelsummary.loc[allwsjchannelsummary['MAU Subs Date'] == 1]\n",
    "mau = mau[['Actual Date','MAU, Apple News+ Subscribers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:11.048827Z",
     "start_time": "2022-01-27T20:40:11.019676Z"
    }
   },
   "outputs": [],
   "source": [
    "allwsjchannelsummary2 = pd.merge(allwsjchannelsummaryweekly, mau, how='left', left_on=['Week Ending'], right_on=['Actual Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:12.521560Z",
     "start_time": "2022-01-27T20:40:11.058514Z"
    }
   },
   "outputs": [],
   "source": [
    "#Opening the worksheet by using Worksheet ID\n",
    "workbook = gc.open_by_key('1Q_mLCBtjCDN0v3xXZPIvHWRxOA8-GZMZSzn_4S4AQFw')\n",
    "#Selecting which sheet to pulling the data\n",
    "sheet = workbook.worksheet('Sheet1')\n",
    "#Pulling the data and transform it to the data frame\n",
    "values = sheet.get_all_values()\n",
    "fiscal = pd.DataFrame(values[1:], columns = values[0])\n",
    "#webstories = pd.DataFrame(values, columns =[0])\n",
    "fiscal['actual_date'] = pd.to_datetime(fiscal['actual_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:12.534207Z",
     "start_time": "2022-01-27T20:40:12.524167Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined = pd.merge(allwsjchannelsummary2, fiscal, how='left', left_on=['Week Ending'], right_on=['actual_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:16.992932Z",
     "start_time": "2022-01-27T20:40:12.538191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sheet is updated successfully\n"
     ]
    }
   ],
   "source": [
    "# Configure the connection \n",
    "scope = ['https://spreadsheets.google.com/feeds']\n",
    "\n",
    "# Give the path to the Service Account Credential json file \n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('/Users/dicharryd/service_token.json',\n",
    "                                                               scope\n",
    "                                                              )\n",
    "# Authorise your Notebook\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "# The sprad sheet ID, which can be taken from the link to the sheet\n",
    "spreadsheet_key = '1VpimYGT1nZ20KmsvR6ILs1dIkC4mlDE_0uMsz6ckCDk'\n",
    "\n",
    "# Set the sheet name you want to upload data to and the start cell where the upload data begins \n",
    "wks_name = 'new_dashboard'\n",
    "cell_of_start_df = 'a1'\n",
    "# upload the dataframe of the clients we want to delete\n",
    "d2g.upload(combined,\n",
    "           spreadsheet_key,\n",
    "           wks_name,\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = cell_of_start_df,\n",
    "           clean=True)\n",
    "print ('The sheet is updated successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOP STORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:21.935830Z",
     "start_time": "2022-01-27T20:40:17.032121Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "features = allwsjarticledetailimport.copy(deep=True)\n",
    "features['Date']= pd.to_datetime(features['Date'])\n",
    "features['date']= pd.to_datetime(features['Date'])\n",
    "features = features[['Date','Where Featured by Apple','date']]\n",
    "features = features[features['Where Featured by Apple'].notna()] #drop only NaN rows\n",
    "\n",
    "start_date = (pd.to_datetime(\"now\") - pd.offsets.MonthBegin(14))\n",
    "end_date = pd.to_datetime(\"now\")\n",
    "mask = (features['Date'] > start_date) & (features['Date'] <= end_date) \n",
    "features = features.loc[mask]\n",
    "\n",
    "#features.sort_values(by='Date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:22.098890Z",
     "start_time": "2022-01-27T20:40:21.956458Z"
    }
   },
   "outputs": [],
   "source": [
    "#CLASSIFY FEATURE TYPE\n",
    "\n",
    "topstories = features[features['Where Featured by Apple'].str.contains('Featured in Top Stories', na=False)]\n",
    "topstories.insert(1,'Feature','Top Stories')\n",
    "topstories.insert(1,'Feature Order','1')\n",
    "#topstories = topstories[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "stocks = features[features['Where Featured by Apple'].str.contains('Featured in Stocks Top Stories', na=False)]\n",
    "stocks.insert(1,'Feature','Stocks Top Stories')\n",
    "stocks.insert(1,'Feature Order','2')\n",
    "#stocks = stocks[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "trending = features[features['Where Featured by Apple'].str.contains('Appeared in Trending Stories', na=False)]\n",
    "trending.insert(1,'Feature','Trending Stories')\n",
    "trending.insert(1,'Feature Order','3')\n",
    "#trending = trending[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "email = features[features['Where Featured by Apple'].str.contains('Featured in Apple Email', na=False)]\n",
    "email.insert(1,'Feature','Apple Email')\n",
    "email.insert(1,'Feature Order','4')\n",
    "#email = email[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "spotlight = features[features['Where Featured by Apple'].str.contains('Featured in Spotlight', na=False)]\n",
    "spotlight.insert(1,'Feature','Spotlight')\n",
    "spotlight.insert(1,'Feature Order','5')\n",
    "#spotlight = spotlight[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "boosted = features[features['Where Featured by Apple'].str.contains('Boosted by Apple Editors', na=False)]\n",
    "boosted.insert(1,'Feature','Boosted by Apple Editors')\n",
    "boosted.insert(1,'Feature Order','6')\n",
    "#boosted = boosted[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "takeover = features[features['Where Featured by Apple'].str.contains('Featured as Today View Takeover', na=False)]\n",
    "takeover.insert(1,'Feature','Today View Takeover')\n",
    "takeover.insert(1,'Feature Order','7')\n",
    "#takeover = takeover[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "newsplusfeed = features[features['Where Featured by Apple'].str.contains('Article Featured in News', na=False)]\n",
    "newsplusfeed.insert(1,'Feature','Article Featured in News+ Feed')\n",
    "newsplusfeed.insert(1,'Feature Order','8')\n",
    "#newsplusfeed = newsplusfeed[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "video = features[features['Where Featured by Apple'].str.contains('Video Featured in Today Feed', na=False)]\n",
    "video.insert(1,'Feature','Video Featured in Today Feed')\n",
    "video.insert(1,'Feature Order','9')\n",
    "#video = video[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "articlefeat = features[features['Where Featured by Apple'].str.contains('Article Featured in Today Feed', na=False)]\n",
    "articlefeat.insert(1,'Feature','Article Featured in Today Feed')\n",
    "articlefeat.insert(1,'Feature Order','10')\n",
    "#articlefeat = articlefeat[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "editorial = features[features['Where Featured by Apple'].str.contains('Editorial', na=False)]\n",
    "editorial.insert(1,'Feature','Featured in an Editorial Group')\n",
    "editorial.insert(1,'Feature Order','11')\n",
    "#editorial = editorial[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "local = features[features['Where Featured by Apple'].str.contains('Local', na=False)]\n",
    "local.insert(1,'Feature','Featured in Local News')\n",
    "local.insert(1,'Feature Order','12')\n",
    "#local = local[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "audiostory = features[features['Where Featured by Apple'].str.contains('Audio Story Published', na=False)]\n",
    "audiostory.insert(1,'Feature','Audio Story Published')\n",
    "audiostory.insert(1,'Feature Order','13')\n",
    "#audiostory = audiostory[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "audiofeed = features[features['Where Featured by Apple'].str.contains('Recommended in Audio Feed', na=False)]\n",
    "audiofeed.insert(1,'Feature','Recommended in Audio Feed')\n",
    "audiofeed.insert(1,'Feature Order','14')\n",
    "#audiofeed = audiofeed[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "newsbriefing = features[features['Where Featured by Apple'].str.contains('Featured in ‚ÄúApple News Today‚Äù Briefing', na=False)]\n",
    "newsbriefing.insert(1,'Feature','Featured in News Briefing')\n",
    "newsbriefing.insert(1,'Feature Order','15')\n",
    "#newsbriefing = newsbriefing[['Region','Date','Feature Order','Feature','Article']]\n",
    "\n",
    "specialtopic = features[features['Where Featured by Apple'].str.contains('Featured in Special Topic', na=False)]\n",
    "specialtopic.insert(1,'Feature','Featured in Special Topic')\n",
    "specialtopic.insert(1,'Feature Order','16')\n",
    "#specialtopic = specialtopic[['Region','Date','Feature Order','Feature','Article']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:26.756780Z",
     "start_time": "2022-01-27T20:40:22.103078Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sheet is updated successfully\n"
     ]
    }
   ],
   "source": [
    "topstories = pd.concat([topstories, stocks, trending, email, spotlight, boosted, takeover, newsplusfeed, video, articlefeat, editorial, local, audiostory, audiofeed, newsbriefing, specialtopic], sort=False)\n",
    "topstories = pd.merge(topstories, fiscal, how='left', left_on=['Date'], right_on=['actual_date'])\n",
    "topstories = topstories.loc[topstories['Feature'] == 'Top Stories']\n",
    "topstories = topstories.groupby(['DJFWID','DJFW','Feature']).count().reset_index()\n",
    "topstories.rename(columns={'Date': 'Count'}, inplace=True) #RENAME COLUMN\n",
    "topstories = topstories[['DJFWID','DJFW','Feature','Count']].reset_index().sort_values(by='DJFWID',ascending=False)\n",
    "\n",
    "# The sprad sheet ID, which can be taken from the link to the sheet\n",
    "spreadsheet_key = '1VpimYGT1nZ20KmsvR6ILs1dIkC4mlDE_0uMsz6ckCDk'\n",
    "\n",
    "# Set the sheet name you want to upload data to and the start cell where the upload data begins \n",
    "wks_name = 'top_stories'\n",
    "cell_of_start_df = 'a1'\n",
    "# upload the dataframe of the clients we want to delete\n",
    "d2g.upload(topstories,\n",
    "           spreadsheet_key,\n",
    "           wks_name,\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = cell_of_start_df,\n",
    "           clean=True)\n",
    "print ('The sheet is updated successfully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T20:40:31.684068Z",
     "start_time": "2022-01-27T20:40:26.760172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sheet is updated successfully\n"
     ]
    }
   ],
   "source": [
    "allwsjnotifications = allwsjnotificationsimport.copy(deep=True)\n",
    "allwsjnotifications['Date']= pd.to_datetime(allwsjnotifications['Date'])\n",
    "allwsjnotifications = pd.merge(allwsjnotifications, fiscal, how='left', left_on=['Date'], right_on=['actual_date'])\n",
    "allwsjnotifications = allwsjnotifications[['DJFWID','Article']]\n",
    "allwsjnotifications.rename(columns={'Article': 'Count'}, inplace=True) #RENAME COLUMN\n",
    "allwsjnotifications = allwsjnotifications.groupby('DJFWID').count().reset_index().sort_values(by='DJFWID',ascending=False)\n",
    "\n",
    "# The sprad sheet ID, which can be taken from the link to the sheet\n",
    "spreadsheet_key = '1VpimYGT1nZ20KmsvR6ILs1dIkC4mlDE_0uMsz6ckCDk'\n",
    "\n",
    "# Set the sheet name you want to upload data to and the start cell where the upload data begins \n",
    "wks_name = 'notifications'\n",
    "cell_of_start_df = 'a1'\n",
    "# upload the dataframe of the clients we want to delete\n",
    "d2g.upload(allwsjnotifications,\n",
    "           spreadsheet_key,\n",
    "           wks_name,\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = cell_of_start_df,\n",
    "           clean=True)\n",
    "print ('The sheet is updated successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
